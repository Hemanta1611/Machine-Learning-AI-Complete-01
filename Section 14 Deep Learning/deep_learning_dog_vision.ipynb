{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Deep Learning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Tensorflow:` \n",
    "\n",
    "1. Write fast deep leaning code in python (able to run on gpu) <br>\n",
    "2. Able to access many pre-built deep learning models <br>\n",
    "3. Whole stack: preprocess, model, deploy <br>\n",
    "4. Originally desined and used in-house by Google (now open-source) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](abc.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Transfer Learning:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take what you know in one domain and apply it to another <br>\n",
    "2. Starting from scratchh can be expensive and time consuming <br>\n",
    "3. Why not tak advantages of what's already out there! <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The workflow of Deep Learning is same as Machine Learning (Scikit-Learn)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_we_are_learning = {\"1\": \"An end-to-end multi-class classification workflow with Tensorflow\",\n",
    "                      \"2\": \"Preprocessing image data(getting it into Tensors)\",\n",
    "                      \"3\": \"Choosing a deep learning model\",\n",
    "                      \"4\": \"Fitting a model to the data (learning patterns)\",\n",
    "                      \"5\": \"Making predictions with a model(using patterns)\",\n",
    "                      \"6\": \"Evaluating model predictions\",\n",
    "                      \"7\": \"Saving and loading models\",\n",
    "                      \"8\": \"Using a trained model to make predictions on custom data\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://www.kaggle.com/c/dog-breed-identification/data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do this project on google colab for access of gpu and faster computation and training.\n",
    "`https://colab.research.google.com/drive/1QAUezsJXm06dy-vk1GHzG4mepav1oyFj?usp=sharing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üß≠ Deep Learning Model Selection Guide\n",
    "\n",
    "> A practical map to help choose the right Deep Learning model based on **data type**, **task**, and **resources**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Start with: What type of data do you have?\n",
    "\n",
    "### üñºÔ∏è Images\n",
    "- **Small dataset (<10k):**  \n",
    "  ‚û§ Use **Transfer Learning** with pretrained models like `ResNet`, `VGG`, `EfficientNet`\n",
    "- **Medium/Large dataset:**  \n",
    "  ‚û§ Use CNN architectures like `ResNet`, `DenseNet`, `EfficientNet`\n",
    "- **Object Detection:**  \n",
    "  ‚û§ Use `Faster R-CNN`, `YOLO`, or `SSD`\n",
    "- **Segmentation:**  \n",
    "  ‚û§ Use `UNet`, `DeepLab`, `Mask R-CNN`\n",
    "- **Image Generation:**  \n",
    "  ‚û§ Use `GANs`, `Stable Diffusion`, `StyleGAN`\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Text (NLP)\n",
    "- **Small dataset:**  \n",
    "  ‚û§ Fine-tune `BERT`, `DistilBERT`\n",
    "- **Large dataset:**  \n",
    "  ‚û§ Use `Transformer` models like `GPT`, `T5`, `BART`\n",
    "- **Sequence prediction:**  \n",
    "  ‚û§ Use `RNN`, `LSTM`, `GRU` (low-resource) or `Transformer`\n",
    "- **Text classification:**  \n",
    "  ‚û§ Use `BERT`, `RoBERTa`, `DeBERTa`\n",
    "- **Text generation:**  \n",
    "  ‚û§ Use `GPT`, `T5`, `LLaMA`\n",
    "\n",
    "---\n",
    "\n",
    "### üîâ Audio\n",
    "- **Classification:**  \n",
    "  ‚û§ Use CNNs on spectrograms or `Wav2Vec`\n",
    "- **Speech-to-text:**  \n",
    "  ‚û§ Use `Whisper`, `DeepSpeech`, `Wav2Vec 2.0`\n",
    "- **Audio/music generation:**  \n",
    "  ‚û§ Use `DiffWave`, `Jukebox`, `AudioLM`\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Time Series\n",
    "- **Univariate:**  \n",
    "  ‚û§ Use `LSTM`, `1D CNN`, `TCN`\n",
    "- **Multivariate:**  \n",
    "  ‚û§ Use `Transformer`, `TFT` (Temporal Fusion Transformer)\n",
    "- **Forecasting:**  \n",
    "  ‚û§ Use `DeepAR`, `N-BEATS`, `Informer`\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Tabular Data\n",
    "- **Small dataset:**  \n",
    "  ‚û§ Prefer classical ML (e.g., XGBoost), or use `TabNet`, `FT-Transformer`\n",
    "- **Large dataset:**  \n",
    "  ‚û§ Use `TabTransformer`, `TabNet`, DNNs with embeddings\n",
    "- **High-cardinality categorical features:**  \n",
    "  ‚û§ Use `TabTransformer`, `FT-Transformer`\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Graph Data\n",
    "- ‚û§ Use `GCN`, `GAT`, `GraphSAGE`, `GIN`, using frameworks like `DGL` or `PyG`\n",
    "\n",
    "---\n",
    "\n",
    "### üßë‚Äçüíª Multimodal Data (e.g., Image + Text)\n",
    "- ‚û§ Use `CLIP` (for joint embeddings)\n",
    "- ‚û§ Use `BLIP-2`, `Flamingo`, `GIT` (image captioning)\n",
    "- ‚û§ Use `Perceiver`, `MM-Transformer`, `LLaVA`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Special Considerations\n",
    "\n",
    "### ‚ö° Need Real-Time / Edge Inference?\n",
    "- Use lightweight models:  \n",
    "  ‚û§ `MobileNet`, `DistilBERT`, `Tiny-YOLO`, `FastSpeech`\n",
    "\n",
    "### üéØ Need Explainability?\n",
    "- Avoid large black-box models (e.g., Transformers)\n",
    "- Prefer:  \n",
    "  ‚û§ `LSTM`, `CNN` with attention  \n",
    "  ‚û§ Or use post-hoc tools like `SHAP`, `LIME`\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Summary Table\n",
    "\n",
    "| Task / Data Type           | Suggested Models                                  |\n",
    "|---------------------------|---------------------------------------------------|\n",
    "| Small image dataset       | Transfer learning (ResNet, VGG, etc.)            |\n",
    "| Large image dataset       | CNNs (ResNet, EfficientNet), Vision Transformers |\n",
    "| Text classification       | BERT, RoBERTa, DistilBERT                         |\n",
    "| Text generation           | GPT, T5, LLaMA                                    |\n",
    "| Time series forecasting   | LSTM, TCN, Informer, DeepAR                       |\n",
    "| Tabular (small)           | Gradient Boosting / TabNet                        |\n",
    "| Graph data                | GCN, GAT, GIN                                     |\n",
    "| Multimodal                | CLIP, Flamingo, BLIP-2, Perceiver                 |\n",
    "| Real-time needs           | MobileNet, DistilBERT, TinyML models              |\n",
    "| Explainable models        | LSTM, CNN + SHAP/LIME                             |\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Tip:** Combine this guide with proper experimentation, validation, and baseline comparison for best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
